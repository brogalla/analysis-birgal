{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98513338",
   "metadata": {},
   "source": [
    "# Add slice of zeros to a bunch of the forcing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "574b1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a37355-8053-46e1-9eab-cfbbe8477f00",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e42b3-e71c-49c6-97c0-da4a90fadc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/33435953/is-it-possible-to-append-to-an-xarray-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e1280-2c59-4513-80ce-5c7299005d43",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a56a2e4a-ac1a-477b-b866-d01b38fd0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_old   = xr.open_dataset(f'/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/bathymetry/domain_cfg-old.nc')\n",
    "domain_new   = xr.open_dataset(f'/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/bathymetry/domain_cfg-20231025.nc')\n",
    "bergmelt_old = xr.open_dataset(f'/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/output/old-forcing/bergmelt.nc')\n",
    "calving_old  = xr.open_dataset(f'/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/output/old-forcing/calving.nc')\n",
    "bfrcoef_old  = xr.open_dataset(f'/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/output/old-forcing/bfr_coef.nc')\n",
    "runoff_old   = xr.open_dataset(f'/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/output/old-forcing/runoff_y1979.nc')\n",
    "shlat2d_old  = xr.open_dataset(f'/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/output/old-forcing/shlat2d.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fae8c-fe58-4fd6-b504-f59cda90ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add slice of points nort of the pre-existing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ca46ca3-3595-458c-9185-aab70fe6091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time_counter', 'y', 'x')\n",
      "('time_counter', 'y', 'x')\n",
      "('time_counter', 'y', 'x')\n",
      "('y', 'x')\n"
     ]
    }
   ],
   "source": [
    "print(bergmelt_old.berg_melt.dims)\n",
    "print(calving_old.soicbclv.dims)\n",
    "print(bfrcoef_old.bfr_coef.dims)\n",
    "print(shlat2d_old.shlat2d.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b4a286f-ccb5-4ea3-b69a-f5ae939bb891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berg_melt\n",
      "bfr_coef\n",
      "soicbclv\n",
      "shlat2d\n"
     ]
    }
   ],
   "source": [
    "vars  = ['berg_melt', 'bfr_coef', 'soicbclv', 'shlat2d']\n",
    "folder_out = '/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/output/old-forcing/extended/'\n",
    "files = glob.glob('/gws/nopw/j04/terrafirma/birgal/NEMO_AIS/output/old-forcing/*.nc')\n",
    "for var in vars:\n",
    "    print(var)\n",
    "    for file in files:\n",
    "        ds = xr.open_dataset(file)\n",
    "        if var in ds:\n",
    "            try:\n",
    "                new_var = np.empty((ds.time_counter.shape[0], domain_new.nav_lon.shape[0], domain_new.nav_lon.shape[1]))\n",
    "                new_var[:] = np.nan\n",
    "                new_var[:,:439,:] = ds[var].values\n",
    "                \n",
    "                ds_new = xr.Dataset(data_vars = {var:([\"time_counter\", \"y\", \"x\"], new_var)},\n",
    "                                    coords    = {'nav_lon': domain_new.nav_lon,\n",
    "                                                 'nav_lat': domain_new.nav_lat,\n",
    "                                                 'time_counter': ds.time_counter})\n",
    "                ds_new.to_netcdf(f\"{folder_out}{file.split('old-forcing/')[1].split('.')[0]}-extended.nc\")\n",
    "            except:\n",
    "                new_var = np.empty((domain_new.nav_lon.shape[0], domain_new.nav_lon.shape[1]))\n",
    "                new_var[:] = np.nan\n",
    "                new_var[:439,:] = ds[var].values\n",
    "                \n",
    "                ds_new = xr.Dataset(data_vars = {var:([\"y\", \"x\"], new_var)},\n",
    "                                    coords    = {'nav_lon': domain_new.nav_lon,\n",
    "                                                 'nav_lat': domain_new.nav_lat})\n",
    "                new_name = file.split('old-forcing/')\n",
    "                ds_new.to_netcdf(f\"{folder_out}{file.split('old-forcing/')[1].split('.')[0]}-extended.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaspy3.10",
   "language": "python",
   "name": "jaspy3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
