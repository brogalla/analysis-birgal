{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ecb046-2069-4731-912e-2764addcc302",
   "metadata": {},
   "source": [
    "# Bias correct atmospheric conditions\n",
    "\n",
    "- spatially varying field that is constant in time\n",
    "- Calculated from the difference between ERA5 1979-2015 time-mean and PACE ensemble-mean and time-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a8a586-bb06-4b50-8024-eeb8d5815aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cmocean\n",
    "import sys\n",
    "sys.path.append('/home/users/birgal/')\n",
    "import pickle\n",
    "from nemo_python_git.utils import fix_lon_range\n",
    "from nemo_python_git.interpolation import regrid_array_cf, regrid_operator_cf, interp_latlon_cf\n",
    "from nemo_python_git.forcing import find_cesm2_file\n",
    "from nemo_python_git.constants import cesm2_ensemble_members\n",
    "from nemo_python_git.ics_obcs import fill_ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c432f9c-2976-4233-8898-96832d5cffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/gws/nopw/j04/anthrofail/birgal/NEMO_AIS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e52b56-2a88-43fd-8d36-59554f4b8609",
   "metadata": {},
   "source": [
    "### Start with thermodynamic variables (TREFHT, QREFHT, FLDS, FSDS, PRECT, PRECS, PSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc55e602-5764-4f33-b260-d4b7d227fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_file = xr.open_dataset('/gws/nopw/j04/anthrofail/birgal/NEMO_AIS/bathymetry/domain_cfg-20240305.nc').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "954a65c5-cc1f-4cfa-b7b9-590c8317b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path     = find_cesm2_file('LE2', 'TREFHT', 'atm', 'daily', '1011.001', 1850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff39c90e-3328-4d45-9400-313d257d4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_file = xr.open_dataset('/gws/nopw/j04/anthrofail/birgal/NEMO_AIS/ERA5-forcing/files/era5_t2m_1979_daily_averages.nc').mean(dim='time')\n",
    "era5_file['longitude'] = fix_lon_range(era5_file['longitude'])\n",
    "era5_ds = era5_file.rename({'longitude':'lon', 'latitude':'lat'}).sortby('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7511c519-19c9-47f7-ad2a-f924faa7bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_mean_interp = interp_latlon_cf(era5_ds, nemo_file.isel(time_counter=0), pster_src=False, periodic_src=True, periodic_nemo=True, method='conservative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a92be1ea-0363-4a6f-aefb-50b3e789cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cesm2_file = xr.open_dataset(file_path)\n",
    "cm2 = cesm2_file.isel(time=(cesm2_file.time.dt.year==1850)).mean(dim='time')\n",
    "cm2['lon'] = fix_lon_range(cm2['lon'])\n",
    "cm2_ds = cm2[['TREFHT']].sortby('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc52b65f-085c-4714-ae5e-b6448ca77d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CESM2_mean_interp = interp_latlon_cf(cm2_ds, nemo_file, pster_src=False, periodic_src=True, periodic_nemo=True, method='conservative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9642c3b-cbcf-47f6-a687-b8de95b1225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CESM2_mean = cesm2_ensemble_time_mean_forcing('LE2', 'TREFHT', year_start=1850, year_end=1851, \n",
    "                                              out_file='/gws/nopw/j04/anthrofail/birgal/NEMO_AIS/climate-forcing/CESM2/LE2/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04b2452e-0054-4ae1-aa60-50c434e614a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def era5_time_mean_forcing(variable, year_start=1979, year_end=2015, out_file=None):\n",
    "\n",
    "    ERA5_ds   = xr.open_mfdataset(f'{base_folder}ERA5-forcing/files/era5_{variable}_*_daily_averages.nc')\n",
    "    ERA5_ds   = ERA5_ds.isel(time=((ERA5_ds.time.dt.year <= year_end)*(ERA5_ds.time.dt.year >= year_start)))\n",
    "    time_mean = ERA5_ds[variable].mean(dim='time')\n",
    "\n",
    "    if out_file:\n",
    "        time_mean.to_netcdf(out_file)\n",
    "\n",
    "    return time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5004c9a-d222-446f-8f81-d3dcd3097462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calculates the time-mean over specified year range for mean of all CESM2 ensemble members in the specified experiment\n",
    "# !!!! but should I be running this on my pre-processed files? or on the original? --- changes what I read in and whether I need to correct lon range\n",
    "# Input:\n",
    "# - expt : string of CESM2 experiment name (e.g. 'LE2')\n",
    "# - variable : string of forcing variable name\n",
    "# - (optional) year_start : start year for time averaging\n",
    "# - (optional) end_year   : end year for time averaging\n",
    "# - (optional) out_file   : path to file to write time mean to NetCDF in case you want to store it\n",
    "# - (optional) ensemble_members : list of strings of ensemble members to average (defaults to all the ones that have been downloaded)\n",
    "def cesm2_ensemble_time_mean_forcing(expt, variable, year_start=1979, year_end=2015, out_file=None, ensemble_members=cesm2_ensemble_members):\n",
    "\n",
    "    # calculate ensemble mean for each year\n",
    "    year_mean = xr.Dataset()\n",
    "    for year in range(year_start, year_end+1):\n",
    "        files_to_open = []\n",
    "        for ens in ensemble_members:\n",
    "            file_path     = find_cesm2_file(expt, variable, 'atm', 'daily', ens, year)\n",
    "            files_to_open += [file_path]\n",
    "        # calculate ensemble mean    \n",
    "        ens_files = xr.open_mfdataset(files_to_open, concat_dim='ens', combine='nested')\n",
    "        ens_year  = ens_files[variable].isel(time=(ens_files.time.dt.year==year))\n",
    "        ens_mean  = ens_year.mean(dim=['time','ens']) # dimensions should be x,y\n",
    "        # save ensemble mean to xarray dataset\n",
    "        if year == year_start:\n",
    "            year_mean = ens_mean\n",
    "        else:\n",
    "            year_mean = xr.concat([year_mean, ens_mean], dim='year')\n",
    "            \n",
    "    # and then calculate time-mean of all ensemble means:\n",
    "    time_mean = year_mean.mean(dim='year')\n",
    "    if out_file:\n",
    "        time_mean.to_netcdf(out_file)\n",
    "    \n",
    "    return time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c0550db-9ae8-4186-9290-1273fe93fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_to_CESM2_varnames = {'t2m':'TREFHT','rsds':'FSDS','rlds':'FLDS','d2m':'QREFHT'}\n",
    "CESM2_to_ERA5_varnames = {'TREFHT':'t2m','FSDS':'rsds','FLDS':'rlds','QREFHT':'d2m'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f874365-2ca4-440c-bf18-1073e71cc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/birgal/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/indexing.py:1621: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid indexer array, does not have integer dtype: array([225.40704, 225.41272, 225.41272, 225.41272, 225.41272, 225.41272,\n       225.41272, 225.41272, 225.41272, 225.41272, 225.41272, 225.4189 ,\n       225.42445, 225.42448, 225.42445, 225.43439, 225.4331 , 225.42445,\n       225.42448, 225.42445, 225.43254, 225.44029, 225.44899, 225.45198,\n       225.46178, 225.46178, 225.46178, 225.46275, 225.46178, 225.46973,\n       225.47552, 225.48836, 225.50256, 225.5163 , 225.51787, 225.53082,\n       225.54535, 225.55983, 225.57637, 225.59503, 225.62721, 225.66626,\n       225.71513, 225.75166, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76048, 225.76045, 225.76048,\n       225.76048, 225.76048, 225.76045, 225.76045, 225.76048, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.70367, 225.54126,\n       225.41096, 225.38655, 225.36464, 225.35754, 225.34277, 225.33093,\n       225.33093, 225.32915, 225.32225, 225.32225, 225.31287, 225.30359,\n       225.29822, 225.29822, 225.29541, 225.28491, 225.28392, 225.28392,\n       225.28394, 225.28392, 225.28386, 225.27734, 225.27727, 225.27727,\n       225.27727, 225.27599, 225.271  , 225.26768, 225.26503, 225.26503,\n       225.26503, 225.26503, 225.26503, 225.26503, 225.26503, 225.26503,\n       225.26503, 225.26503, 225.26503, 225.26503, 225.26503, 225.26503,\n       225.26503, 225.26503, 225.26503, 225.2625 , 225.2594 , 225.2594 ,\n       225.2594 , 225.2594 , 225.2594 , 225.2594 , 225.2594 , 225.2594 ,\n       225.2594 , 225.2594 , 225.26082, 225.26503, 225.26501, 225.26501,\n       225.26503, 225.26503, 225.26668, 225.271  , 225.271  , 225.271  ,\n       225.27098, 225.271  , 225.271  , 225.271  , 225.27098, 225.27098,\n       225.27602, 225.27727, 225.27727, 225.27728, 225.27728, 225.28162,\n       225.28392, 225.28392, 225.28394, 225.28894, 225.27168, 225.2351 ,\n       225.14168, 225.08891, 225.0717 , 225.06181, 225.05342, 225.05147,\n       225.05394, 225.04189, 225.04655, 225.03911, 225.03679, 225.03679,\n       225.04317, 225.05162, 225.05449, 225.05449, 225.0744 , 225.07733,\n       225.0814 , 225.08702, 225.09227, 225.10083, 225.10083, 225.10661,\n       225.12482, 225.125  , 225.13094, 225.14986, 225.15608, 225.16469,\n       225.17493, 225.19414, 225.22139, 225.22816, 225.23987, 225.25462,\n       225.27313, 225.30322, 225.33647, 225.35913, 225.36359, 225.38097],\n      dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43matm_bias_correction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCESM2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTREFHT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1979\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1981\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 28\u001b[0m, in \u001b[0;36matm_bias_correction\u001b[0;34m(source, variable, expt, year_start, year_end, ensemble_mean_file, era5_mean_file, nemo_grid)\u001b[0m\n\u001b[1;32m     26\u001b[0m CESM2_source \u001b[38;5;241m=\u001b[39m CESM2_time_mean\u001b[38;5;241m.\u001b[39msortby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m ERA5_source  \u001b[38;5;241m=\u001b[39m ERA5_time_mean\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39msortby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m CESM2_mean_interp \u001b[38;5;241m=\u001b[39m \u001b[43minterp_latlon_cf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCESM2_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnemo_grid_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpster_src\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodic_src\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodic_nemo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconservative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m ERA5_mean_interp  \u001b[38;5;241m=\u001b[39m interp_latlon_cf(ERA5_source , nemo_grid_ds, pster_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, periodic_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, periodic_nemo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconservative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseems to have made it through function\u001b[39m\u001b[38;5;124m'\u001b[39m, CESM2_mean_interp, ERA5_mean_interp)\n",
      "File \u001b[0;32m~/nemo_python_git/interpolation.py:426\u001b[0m, in \u001b[0;36minterp_latlon_cf\u001b[0;34m(source, nemo, pster_src, periodic_src, periodic_nemo, method)\u001b[0m\n\u001b[1;32m    424\u001b[0m data_cf \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m source:\n\u001b[0;32m--> 426\u001b[0m     data_cf\u001b[38;5;241m.\u001b[39mappend(construct_cf(\u001b[43msource\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m]\u001b[49m, x_src, y_src, lon\u001b[38;5;241m=\u001b[39mlon_src, lat\u001b[38;5;241m=\u001b[39mlat_src, lon_bounds\u001b[38;5;241m=\u001b[39mlon_bounds_src, lat_bounds\u001b[38;5;241m=\u001b[39mlat_bounds_src))\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Get NEMO grid in CF format\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Figure out some dimension and coordinate names\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglamt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nemo:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# domain_cfg type\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/dataarray.py:891\u001b[0m, in \u001b[0;36mDataArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_coord(key)\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# xarray-style array indexing\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_item_key_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/dataarray.py:1519\u001b[0m, in \u001b[0;36mDataArray.isel\u001b[0;34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m indexers \u001b[38;5;241m=\u001b[39m either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_fancy_indexer(idx) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indexers\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1519\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_isel_fancy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_dims\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# Much faster algorithm for when all indexers are ints, slices, one-dimensional\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;66;03m# lists, or zero or one-dimensional np.ndarray's\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/dataset.py:3074\u001b[0m, in \u001b[0;36mDataset._isel_fancy\u001b[0;34m(self, indexers, drop, missing_dims)\u001b[0m\n\u001b[1;32m   3070\u001b[0m var_indexers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3071\u001b[0m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m valid_indexers\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m var\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m   3072\u001b[0m }\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var_indexers:\n\u001b[0;32m-> 3074\u001b[0m     new_var \u001b[38;5;241m=\u001b[39m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_indexers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3075\u001b[0m     \u001b[38;5;66;03m# drop scalar coordinates\u001b[39;00m\n\u001b[1;32m   3076\u001b[0m     \u001b[38;5;66;03m# https://github.com/pydata/xarray/issues/6554\u001b[39;00m\n\u001b[1;32m   3077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords \u001b[38;5;129;01mand\u001b[39;00m drop \u001b[38;5;129;01mand\u001b[39;00m new_var\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/variable.py:1034\u001b[0m, in \u001b[0;36mVariable.isel\u001b[0;34m(self, indexers, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m indexers \u001b[38;5;241m=\u001b[39m drop_dims_from_indexers(indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims, missing_dims)\n\u001b[1;32m   1033\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(indexers\u001b[38;5;241m.\u001b[39mget(dim, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[0;32m-> 1034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/variable.py:798\u001b[0m, in \u001b[0;36mVariable.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    786\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new Variable object whose contents are consistent with\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m    getting the provided key from the underlying data.\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;124;03m    array `x.values` directly.\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m     dims, indexer, new_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_broadcast_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n\u001b[1;32m    801\u001b[0m     data \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mapply_indexer(indexable, indexer)\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/variable.py:656\u001b[0m, in \u001b[0;36mVariable._broadcast_indexes\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    654\u001b[0m         dims\u001b[38;5;241m.\u001b[39mappend(d)\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(dims)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(dims):\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_broadcast_indexes_outer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_indexes_vectorized(key)\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/variable.py:725\u001b[0m, in \u001b[0;36mVariable._broadcast_indexes_outer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    722\u001b[0m             (k,) \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(k)\n\u001b[1;32m    723\u001b[0m     new_key\u001b[38;5;241m.\u001b[39mappend(k)\n\u001b[0;32m--> 725\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dims, \u001b[43mOuterIndexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cf-env/lib/python3.12/site-packages/xarray/core/indexing.py:435\u001b[0m, in \u001b[0;36mOuterIndexer.__init__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_duck_array(k):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(k\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    436\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid indexer array, does not have integer dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         )\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    440\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid indexer array for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; must be scalar \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor have 1 dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid indexer array, does not have integer dtype: array([225.40704, 225.41272, 225.41272, 225.41272, 225.41272, 225.41272,\n       225.41272, 225.41272, 225.41272, 225.41272, 225.41272, 225.4189 ,\n       225.42445, 225.42448, 225.42445, 225.43439, 225.4331 , 225.42445,\n       225.42448, 225.42445, 225.43254, 225.44029, 225.44899, 225.45198,\n       225.46178, 225.46178, 225.46178, 225.46275, 225.46178, 225.46973,\n       225.47552, 225.48836, 225.50256, 225.5163 , 225.51787, 225.53082,\n       225.54535, 225.55983, 225.57637, 225.59503, 225.62721, 225.66626,\n       225.71513, 225.75166, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76048, 225.76045, 225.76048,\n       225.76048, 225.76048, 225.76045, 225.76045, 225.76048, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.76045, 225.76045,\n       225.76045, 225.76045, 225.76045, 225.76045, 225.70367, 225.54126,\n       225.41096, 225.38655, 225.36464, 225.35754, 225.34277, 225.33093,\n       225.33093, 225.32915, 225.32225, 225.32225, 225.31287, 225.30359,\n       225.29822, 225.29822, 225.29541, 225.28491, 225.28392, 225.28392,\n       225.28394, 225.28392, 225.28386, 225.27734, 225.27727, 225.27727,\n       225.27727, 225.27599, 225.271  , 225.26768, 225.26503, 225.26503,\n       225.26503, 225.26503, 225.26503, 225.26503, 225.26503, 225.26503,\n       225.26503, 225.26503, 225.26503, 225.26503, 225.26503, 225.26503,\n       225.26503, 225.26503, 225.26503, 225.2625 , 225.2594 , 225.2594 ,\n       225.2594 , 225.2594 , 225.2594 , 225.2594 , 225.2594 , 225.2594 ,\n       225.2594 , 225.2594 , 225.26082, 225.26503, 225.26501, 225.26501,\n       225.26503, 225.26503, 225.26668, 225.271  , 225.271  , 225.271  ,\n       225.27098, 225.271  , 225.271  , 225.271  , 225.27098, 225.27098,\n       225.27602, 225.27727, 225.27727, 225.27728, 225.27728, 225.28162,\n       225.28392, 225.28392, 225.28394, 225.28894, 225.27168, 225.2351 ,\n       225.14168, 225.08891, 225.0717 , 225.06181, 225.05342, 225.05147,\n       225.05394, 225.04189, 225.04655, 225.03911, 225.03679, 225.03679,\n       225.04317, 225.05162, 225.05449, 225.05449, 225.0744 , 225.07733,\n       225.0814 , 225.08702, 225.09227, 225.10083, 225.10083, 225.10661,\n       225.12482, 225.125  , 225.13094, 225.14986, 225.15608, 225.16469,\n       225.17493, 225.19414, 225.22139, 225.22816, 225.23987, 225.25462,\n       225.27313, 225.30322, 225.33647, 225.35913, 225.36359, 225.38097],\n      dtype=float32)"
     ]
    }
   ],
   "source": [
    "atm_bias_correction('CESM2', 'TREFHT', year_start=1979, year_end=1981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5afe8f64-2589-4289-8a6c-96945eb0634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atm_bias_correction(source, variable, expt='LE2', year_start=1979, year_end=2015, \n",
    "                        ensemble_mean_file=None, era5_mean_file=None,\n",
    "                        nemo_grid='/gws/nopw/j04/anthrofail/birgal/NEMO_AIS/bathymetry/domain_cfg-20240305.nc'):\n",
    "\n",
    "    # NEMO configuration domain_cfg file for regridding\n",
    "    nemo_grid_ds = xr.open_dataset(nemo_grid).squeeze()\n",
    "    \n",
    "    # process_forcing_for_correction(source, variable)\n",
    "    if source=='CESM2':\n",
    "        # Read in ensemble time mean (or calculate it)\n",
    "        if ensemble_mean_file:\n",
    "            CESM2_time_mean = xr.open_dataset(ensemble_mean_file)\n",
    "        else:\n",
    "            CESM2_time_mean = cesm2_ensemble_time_mean_forcing(expt, variable, year_start=year_start, year_end=year_end)\n",
    "\n",
    "        # Read in time mean of ERA5 files (or calculate it)\n",
    "        if era5_mean_file:\n",
    "            ERA5_time_mean = xr.open_dataset(era5_mean_file)\n",
    "        else:\n",
    "            varname = CESM2_to_ERA5_varnames[variable]\n",
    "            ERA5_time_mean = era5_time_mean_forcing(varname, year_start=year_start, year_end=year_end)\n",
    "        \n",
    "        # Regrid time means to NEMO configuration grid, so that they can be used to bias correct\n",
    "        CESM2_time_mean['lon'] = fix_lon_range(CESM2_time_mean['lon'])        \n",
    "        ERA5_time_mean['longitude']  = fix_lon_range(ERA5_time_mean['longitude'])        \n",
    "        CESM2_source = CESM2_time_mean.sortby('lon')\n",
    "        ERA5_source  = ERA5_time_mean.rename({'longitude':'lon', 'latitude':'lat'}).sortby('lon')\n",
    "        CESM2_mean_interp = interp_latlon_cf(CESM2_source, nemo_grid_ds, pster_src=False, periodic_src=True, periodic_nemo=True, method='conservative')\n",
    "        ERA5_mean_interp  = interp_latlon_cf(ERA5_source , nemo_grid_ds, pster_src=False, periodic_src=True, periodic_nemo=True, method='conservative')\n",
    "        \n",
    "        print('seems to have made it through function', CESM2_mean_interp, ERA5_mean_interp)\n",
    "        # # thermodynamic correction\n",
    "        # if variable in ['TREFHT','QREFHT','FLDS','FSDS']:\n",
    "        #     print('Correcting thermodynamics')\n",
    "        #     thermo_correction(variable, CESM2_mean_interp, ERA5_mean_interp, out_file)\n",
    "            \n",
    "        # # wind correction\n",
    "        # elif variable in ['UBOT','VBOT']:\n",
    "        #     print('Correcting katabatic winds')\n",
    "        #     katabatic_correction(variable, CESM2_mean_interp, ERA5_mean_interp, out_file)\n",
    "        # else:\n",
    "        #     raise Exception(f'Variable {variable} does not need bias correction. Check that this is true.')\n",
    "    else:\n",
    "        raise Exception(\"Bias correction currently only set up to correct CESM2, sorry you'll need to write some more code\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def thermo_correction():\n",
    "\n",
    "    # name remapping for variables from ERA5 dataset to CESM2 dataset\n",
    "    ERA5_to_CESM2_varnames = {'t2m':'TREFHT','rsds':'FSDS','rlds':'FLDS','d2m':'QREFHT'} # also consider adding this to the constants file\n",
    "                                         \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b54712-1798-4ead-a693-ddb78a5e4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a correction file for a thermodynamic variable, which will add a spatially-varying offset to UKESM/PACE data so that\n",
    "# it matches ERA5 data in the time-mean.\n",
    "def thermo_correction (grid_dir, var_name, cmip_file, era5_file, out_file, prec=64):\n",
    "\n",
    "    grid = Grid(grid_dir)\n",
    "    data = []\n",
    "    for fname in [cmip_file, era5_file]:\n",
    "        data.append(read_netcdf(fname, var_name))\n",
    "    data_diff = data[1] - data[0]\n",
    "    if len(data_diff.shape) == 2:\n",
    "        latlon_plot(data_diff, grid, ctype='plusminus', figsize=(10,6))\n",
    "    else:\n",
    "        titles = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'July', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
    "        fig, gs, cax = set_panels('3x4+1C1')\n",
    "        cmap, vmin, vmax = set_colours(data_diff, ctype='plusminus')\n",
    "        for n in range(12+1):\n",
    "            if n == 12:\n",
    "                ax = plt.subplot(gs[0,3])\n",
    "                img = ax.pcolormesh(np.mean(data_diff,axis=0), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                ax.set_title('Annual')\n",
    "            else:\n",
    "                ax = plt.subplot(gs[n//4+1, n%4])\n",
    "                img = ax.pcolormesh(data_diff[n,:], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                ax.set_title(titles[n])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.axis('tight')\n",
    "        plt.colorbar(img, cax=cax, orientation='horizontal')\n",
    "        plt.text(0.05, 0.95, var_name+' correction', transform=fig.transFigure, fontsize=20, ha='left', va='top')\n",
    "        finished_plot(fig, fig_name=var_name+'_correction.png')\n",
    "    write_binary(data_diff, out_file, prec=prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45e338-a5ba-44af-9071-a61bee77f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read forcing (var='wind' or 'thermo') from a given atmospheric dataset (source='ERA5', 'UKESM', or 'PACE'). \n",
    "# Time-average, ensemble-average (if PACE) and interpolate to the MITgcm grid. Save the otuput to a NetCDF file. \n",
    "# This will be used to create spatially-varying, time-constant bias correction files in the functions katabatic_correction\n",
    "# and thermo_correction. Can also set monthly_clim=True to get monthly climatology instead of constant in time.\n",
    "def process_forcing_for_correction (source, mit_grid_dir, out_file, in_dir=None, start_year=1979, end_year=None, monthly_clim=False):\n",
    "\n",
    "    # Set parameters based on source dataset\n",
    "    if source == 'ERA5':\n",
    "        if in_dir is None:\n",
    "            # Path on BAS servers\n",
    "            in_dir = '/data/oceans_input/processed_input_data/ERA5/'\n",
    "        file_head = 'ERA5_'\n",
    "        gtype = ['t', 't', 't', 't', 't']\n",
    "        per_day = 4\n",
    "    elif source == 'PACE':\n",
    "        if in_dir is None:\n",
    "            # Path on BAS servers\n",
    "            in_dir = '/data/oceans_input/processed_input_data/CESM/PACE_new/'\n",
    "        file_head = 'PACE_ens'\n",
    "        num_ens = 20\n",
    "        missing_ens = 13\n",
    "        var_names_in = ['TREFHT', 'QBOT', 'PRECT', 'FSDS', 'FLDS']\n",
    "        monthly = [False, False, False, True, True]\n",
    "        gtype = ['t', 't', 't', 't', 't']\n",
    "    else:\n",
    "        print(('Error (process_forcing_for_correction): invalid source ' + source))\n",
    "        sys.exit()\n",
    "    \n",
    "    # Set parameters based on variable type\n",
    "    var_names = ['atemp', 'aqh', 'precip', 'swdown', 'lwdown']\n",
    "    units = ['degC', '1', 'm/s', 'W/m^2', 'W/m^2']\n",
    "    # Check end_year is defined\n",
    "    if end_year is None:\n",
    "        print('Error (process_forcing_for_correction): must set end_year. Typically use 2014 for WSFRIS and 2013 for PACE.')\n",
    "        sys.exit()\n",
    "\n",
    "    mit_grid_dir = real_dir(mit_grid_dir)\n",
    "    in_dir = real_dir(in_dir)\n",
    "\n",
    "    print('Building grids')\n",
    "    if source == 'ERA5':\n",
    "        forcing_grid = ERA5Grid()\n",
    "    elif source == 'PACE':\n",
    "        forcing_grid = CAMGrid()\n",
    "    mit_grid = Grid(mit_grid_dir)\n",
    "\n",
    "    if monthly_clim:\n",
    "        dim_code = 'xyt'\n",
    "    else:\n",
    "        dim_code = 'xy'\n",
    "    ncfile = NCfile(out_file, mit_grid, dim_code)\n",
    "\n",
    "    # Loop over variables\n",
    "    for n in range(len(var_names)):\n",
    "        print(('Processing variable ' + var_names[n]))\n",
    "        # Read the data, time-integrating as we go\n",
    "        data = None\n",
    "        num_time = 0\n",
    "\n",
    "        if source == 'ERA5':\n",
    "            # Loop over years\n",
    "            for year in range(start_year, end_year+1):\n",
    "                file_path = in_dir + file_head + var_names[n] + '_' + str(year)\n",
    "                data_tmp = read_binary(file_path, [forcing_grid.nx, forcing_grid.ny], 'xyt')\n",
    "                if monthly_clim:\n",
    "                    # Average over each month\n",
    "                    data_sum = np.zeros([12, data_tmp.shape[1], data_tmp.shape[2]])\n",
    "                    t = 0\n",
    "                    for m in range(12):\n",
    "                        nt = days_per_month(m+1, year)*per_day\n",
    "                        data_sum[m,:] = np.mean(data_tmp[t:t+nt,:], axis=0)\n",
    "                        t += nt\n",
    "                    num_time += 1  # in years\n",
    "                else:\n",
    "                    # Integrate over entire year\n",
    "                    data_sum = np.sum(data_tmp, axis=0)\n",
    "                    num_time += data_tmp.shape[0]  # in timesteps\n",
    "                if data is None:\n",
    "                    data = data_sum\n",
    "                else:\n",
    "                    data += data_sum\n",
    "                    \n",
    "        elif source == 'PACE':\n",
    "            # Loop over years\n",
    "            for year in range(start_year, end_year+1):\n",
    "                # Loop over ensemble members\n",
    "                data_tmp = None\n",
    "                num_ens_tmp = 0\n",
    "                for ens in range(1, num_ens+1):\n",
    "                    file_path = in_dir + file_head + str(ens).zfill(2) + '_' + var_names_in[n] + '_' + str(year)\n",
    "                    data_tmp_ens = read_binary(file_path, [forcing_grid.nx, forcing_grid.ny], 'xyt')\n",
    "                    if data_tmp is None:\n",
    "                        data_tmp = data_tmp_ens\n",
    "                    else:\n",
    "                        data_tmp += data_tmp_ens\n",
    "                    num_ens_tmp += 1\n",
    "                # Ensemble mean for this year\n",
    "                data_tmp /= num_ens_tmp\n",
    "                # Now accumulate time integral                    \n",
    "                if monthly_clim:\n",
    "                    data_sum = np.zeros([12, data_tmp.shape[1], data_tmp.shape[2]])\n",
    "                    t = 0\n",
    "                    for m in range(12):\n",
    "                        if monthly[n]:\n",
    "                            # Already have monthly averages\n",
    "                            data_sum[m,:] = data_tmp[m,:]\n",
    "                        else:\n",
    "                            ndays = days_per_month(m+1, year, allow_leap=False)\n",
    "                            data_sum[m,:] = np.mean(data_tmp[t:t+ndays,:], axis=0)\n",
    "                            t += ndays\n",
    "                    num_time += 1\n",
    "                else:\n",
    "                    if monthly[n]:\n",
    "                        # Have to weight monthly averages\n",
    "                        for m in range(12):\n",
    "                            ndays = days_per_month(m+1, year, allow_leap=False)\n",
    "                            data_tmp[m,:] *= ndays\n",
    "                            num_time += ndays\n",
    "                    else:\n",
    "                        num_time += data_tmp.shape[0]\n",
    "                    data_sum = np.sum(data_tmp, axis=0)\n",
    "                if data is None:\n",
    "                    data = data_sum\n",
    "                else:\n",
    "                    data += data_sum\n",
    "\n",
    "        # Now convert from time-integral to time-average\n",
    "        data /= num_time\n",
    "\n",
    "        forcing_lon, forcing_lat = forcing_grid.get_lon_lat(gtype=gtype[n], dim=1)\n",
    "        # Get longitude in the range -180 to 180, then split and rearrange so it's monotonically increasing        \n",
    "        forcing_lon = fix_lon_range(forcing_lon)\n",
    "        i_split = np.nonzero(forcing_lon < 0)[0][0]\n",
    "        forcing_lon = split_longitude(forcing_lon, i_split)\n",
    "        data = split_longitude(data, i_split)\n",
    "        # Now interpolate to MITgcm tracer grid        \n",
    "        mit_lon, mit_lat = mit_grid.get_lon_lat(gtype='t', dim=1)\n",
    "        print('Interpolating')\n",
    "        if monthly_clim:\n",
    "            data_interp = np.empty([12, mit_grid.ny, mit_grid.nx])\n",
    "            for m in range(12):\n",
    "                print(('...month ' + str(m+1)))\n",
    "                data_interp[m,:] = interp_reg_xy(forcing_lon, forcing_lat, data[m,:], mit_lon, mit_lat)\n",
    "        else:\n",
    "            data_interp = interp_reg_xy(forcing_lon, forcing_lat, data, mit_lon, mit_lat)\n",
    "        print(('Saving to ' + out_file))\n",
    "        ncfile.add_variable(var_names[n], data_interp, dim_code, units=units[n])\n",
    "\n",
    "    ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185341a-f612-4dca-b86d-4d802a80f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build katabatic correction files which scale and rotate the winds in a band around the coast. The arguments cmip_file and\n",
    "# era5_file are the outputs of process_forcing_for_correction, for UKESM/PACE and ERA5 respectively.\n",
    "# Update 13 March 2020: Can set bounds on region in domain to apply this correction to. For example, in PAS \n",
    "# can set xmin=-90 to only correct in the eastern part of the domain. \n",
    "def katabatic_correction (grid_dir, cmip_file, era5_file, out_file_scale, out_file_rotate, scale_dist=150., scale_cap=3, xmin=None, xmax=None, ymin=None, ymax=None, prec=64):\n",
    "\n",
    "    var_names = ['uwind', 'vwind']\n",
    "    # Radius for smoothing\n",
    "    sigma = 2\n",
    "\n",
    "    print('Building grid')\n",
    "    grid = Grid(grid_dir)\n",
    "    print('Selecting coastal points')\n",
    "    coast_mask = grid.get_coast_mask(ignore_iceberg=True)\n",
    "    lon_coast = grid.lon_2d[coast_mask].ravel()\n",
    "    lat_coast = grid.lat_2d[coast_mask].ravel()\n",
    "    if xmin is None:\n",
    "        xmin = np.amin(grid.lon_2d)\n",
    "    if xmax is None:\n",
    "        xmax = np.amax(grid.lon_2d)\n",
    "    if ymin is None:\n",
    "        ymin = np.amin(grid.lat_2d)\n",
    "    if ymax is None:\n",
    "        ymax = np.amax(grid.lat_2d)\n",
    "\n",
    "    print('Calculating winds in polar coordinates')\n",
    "    magnitudes = []\n",
    "    angles = []\n",
    "    for fname in [cmip_file, era5_file]:\n",
    "        u = read_netcdf(fname, var_names[0])\n",
    "        v = read_netcdf(fname, var_names[1])\n",
    "        magnitudes.append(np.sqrt(u**2 + v**2))\n",
    "        angle = np.arctan2(v,u)\n",
    "        angles.append(angle)\n",
    "\n",
    "    print('Calculating corrections')\n",
    "    # Take minimum of the ratio of ERA5 to CMIP wind magnitude, and the scale cap\n",
    "    scale = np.minimum(magnitudes[1]/magnitudes[0], scale_cap)\n",
    "    # Smooth and mask the land and ice shelf\n",
    "    scale = mask_land_ice(smooth_xy(scale, sigma=sigma), grid)\n",
    "    # Take difference in angles\n",
    "    rotate = angles[1] - angles[0]\n",
    "    # Take mod 2pi when necessary\n",
    "    index = rotate < -np.pi\n",
    "    rotate[index] += 2*np.pi\n",
    "    index = rotate > np.pi\n",
    "    rotate[index] -= 2*np.pi\n",
    "    # Smoothing would be weird with the periodic angle, so just mask\n",
    "    rotate = mask_land_ice(rotate, grid)\n",
    "\n",
    "    print('Calculating distance from the coast')\n",
    "    min_dist = None\n",
    "    # Loop over all the coastal points\n",
    "    for i in range(lon_coast.size):\n",
    "        # Skip over any points that are out of bounds\n",
    "        if lon_coast[i] < xmin or lon_coast[i] > xmax or lat_coast[i] < ymin or lat_coast[i] > ymax:\n",
    "            continue\n",
    "        # Calculate distance of every point in the model grid to this specific coastal point, in km\n",
    "        dist_to_pt = dist_btw_points([lon_coast[i], lat_coast[i]], [grid.lon_2d, grid.lat_2d])*1e-3\n",
    "        if min_dist is None:\n",
    "            # Initialise the array\n",
    "            min_dist = dist_to_pt\n",
    "        else:\n",
    "            # Figure out which cells have this coastal point as the closest one yet, and update the array\n",
    "            index = dist_to_pt < min_dist\n",
    "            min_dist[index] = dist_to_pt[index]\n",
    "\n",
    "    print('Tapering function offshore')\n",
    "    # Cosine function moving from scaling factor to 1 over distance of scale_dist km offshore\n",
    "    scale_tapered = (min_dist < scale_dist)*(scale - 1)*np.cos(np.pi/2*min_dist/scale_dist) + 1\n",
    "    # For the rotation, move from scaling factor to 0\n",
    "    rotate_tapered = (min_dist < scale_dist)*rotate*np.cos(np.pi/2*min_dist/scale_dist)    \n",
    "\n",
    "    print('Plotting')\n",
    "    data_to_plot = [min_dist, scale_tapered, rotate_tapered]\n",
    "    titles = ['Distance to coast (km)', 'Scaling factor', 'Rotation factor']\n",
    "    ctype = ['basic', 'ratio', 'plusminus']\n",
    "    fig_names = ['min_dist.png', 'scale.png', 'rotate.png']\n",
    "    for i in range(len(data_to_plot)):\n",
    "        for fig_name in [None, fig_names[i]]:\n",
    "            latlon_plot(data_to_plot[i], grid, ctype=ctype[i], include_shelf=False, title=titles[i], figsize=(10,6), fig_name=fig_name)\n",
    "\n",
    "    print('Writing to file')\n",
    "    fields = [scale_tapered, rotate_tapered]\n",
    "    out_files = [out_file_scale, out_file_rotate]\n",
    "    for n in range(len(fields)):\n",
    "        # Replace mask with zeros\n",
    "        mask = fields[n].mask\n",
    "        data = fields[n].data\n",
    "        data[mask] = 0\n",
    "        write_binary(data, out_files[n], prec=prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6034c-a970-41a8-a07f-0609a070e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a correction file for a thermodynamic variable, which will add a spatially-varying offset to UKESM/PACE data so that\n",
    "# it matches ERA5 data in the time-mean.\n",
    "def thermo_correction (grid_dir, var_name, cmip_file, era5_file, out_file, prec=64):\n",
    "\n",
    "    grid = Grid(grid_dir)\n",
    "    data = []\n",
    "    for fname in [cmip_file, era5_file]:\n",
    "        data.append(read_netcdf(fname, var_name))\n",
    "    data_diff = data[1] - data[0]\n",
    "    if len(data_diff.shape) == 2:\n",
    "        latlon_plot(data_diff, grid, ctype='plusminus', figsize=(10,6))\n",
    "    else:\n",
    "        titles = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'July', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
    "        fig, gs, cax = set_panels('3x4+1C1')\n",
    "        cmap, vmin, vmax = set_colours(data_diff, ctype='plusminus')\n",
    "        for n in range(12+1):\n",
    "            if n == 12:\n",
    "                ax = plt.subplot(gs[0,3])\n",
    "                img = ax.pcolormesh(np.mean(data_diff,axis=0), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                ax.set_title('Annual')\n",
    "            else:\n",
    "                ax = plt.subplot(gs[n//4+1, n%4])\n",
    "                img = ax.pcolormesh(data_diff[n,:], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                ax.set_title(titles[n])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.axis('tight')\n",
    "        plt.colorbar(img, cax=cax, orientation='horizontal')\n",
    "        plt.text(0.05, 0.95, var_name+' correction', transform=fig.transFigure, fontsize=20, ha='left', va='top')\n",
    "        finished_plot(fig, fig_name=var_name+'_correction.png')\n",
    "    write_binary(data_diff, out_file, prec=prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e762adc-270a-4dce-8c44-5ce3e0fe4dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf-env",
   "language": "python",
   "name": "cf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
